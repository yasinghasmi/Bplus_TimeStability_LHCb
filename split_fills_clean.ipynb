{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9dc6d5d",
   "metadata": {},
   "source": [
    "# Notebook: split by FILL + clean per-block (B2OC/B2CC)\n",
    "\n",
    "Load ROOT trees per block, exclude known bad runs, write one cleaned per-block file, and write per-FILL files that pass a minimum-entries cut.\n",
    "\n",
    "**Important notes**\n",
    "- **Input:** `data/real_5to8_raw/…` - this folder only has blocks **5–8** (earlier blocks were tests). Monte Carlo is in `data/monte_carlo/` and not used here.\n",
    "- **Output:** `data/processed/`\n",
    "- **Filenames:** per-block → `YYYY_DECAY_B{block}.root`; per-FILL → `YYYY_DECAY_B{block}_F{fill}.root`.\n",
    "- **Bad runs:** defined below.\n",
    "- **Threshold:** `MIN_ENTRIES` controls writing per-FILL files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8125555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as r\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "r.ROOT.EnableImplicitMT()  # allow ROOT to parallelize\n",
    "\n",
    "# Fixed locations\n",
    "DATA_RAW = Path(\"data/real_5to8_raw\")   # inputs: blocks 5–8\n",
    "DATA_PROCESSED = Path(\"data/processed\") # outputs\n",
    "DATA_PROCESSED.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "YEAR = 2024 # Will be used for name of the files\n",
    "MIN_ENTRIES = 20_000  # per-FILL write threshold\n",
    "\n",
    "# Bad runs to be excluded\n",
    "BAD_RUNS = {303681, 304475, 304487, 304488, 304489, 304490, 304491}\n",
    "\n",
    "# Inputs (wildcards or single files under DATA_RAW)\n",
    "files_info_b2oc = [\n",
    "    {\"filename\": str(DATA_RAW / \"00289228_00000001_1.highstats-Small-B2OC-UP.root\"),   \"block\": 5},\n",
    "    {\"filename\": str(DATA_RAW / \"00289233_00000001_1.highstats-Small-B2OC-DOWN.root\"), \"block\": 6},\n",
    "    {\"filename\": str(DATA_RAW / \"00289239_00000001_1.highstats-Small-B2OC-DOWN.root\"), \"block\": 7},\n",
    "    {\"filename\": str(DATA_RAW / \"00289237_00000001_1.highstats-Small-B2OC-UP.root\"),   \"block\": 8},\n",
    "]\n",
    "\n",
    "files_info_b2cc = [\n",
    "    {\"filename\": str(DATA_RAW / \"00289229_0000000*_1.highstats-Small-B2CC-UP.root\"),   \"block\": 5},\n",
    "    {\"filename\": str(DATA_RAW / \"00289331_0000000*_1.highstats-Small-B2CC-DOWN.root\"), \"block\": 6},\n",
    "    {\"filename\": str(DATA_RAW / \"00289235_0000000*_1.highstats-Small-B2CC-DOWN.root\"), \"block\": 7},\n",
    "    {\"filename\": str(DATA_RAW / \"00289231_0000000*_1.highstats-Small-B2CC-UP.root\"),   \"block\": 8},\n",
    "]\n",
    "\n",
    "# Snapshot options\n",
    "SNAPSHOT_OPTS = r.RDF.RSnapshotOptions()\n",
    "SNAPSHOT_OPTS.fMode = \"RECREATE\"\n",
    "SNAPSHOT_OPTS.fCompressionAlgorithm = 1  # ZLIB\n",
    "SNAPSHOT_OPTS.fCompressionLevel = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a0a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _outfile(decay: str, block: int, fill: Optional[int]) -> Path:\n",
    "    \"\"\"Build output path under data/processed with deterministic naming.\"\"\"\n",
    "    name = f\"{YEAR}_{decay}_B{block}.root\" if fill is None else f\"{YEAR}_{decay}_B{block}_F{fill}.root\"\n",
    "    return DATA_PROCESSED / name\n",
    "\n",
    "def _bad_expr() -> str:\n",
    "    \"\"\"Return a ROOT cut to exclude bad runs.\"\"\"\n",
    "    return \"true\" if not BAD_RUNS else \" && \".join(f\"run != {r}\" for r in sorted(BAD_RUNS))\n",
    "\n",
    "def process_blocks(files_info: list[dict], treename: str, decay_label: str) -> None:\n",
    "    \"\"\"\n",
    "    Merge all input files per block, apply (block && !bad_runs),\n",
    "    write one per-block file and per-FILL files (>= MIN_ENTRIES).\n",
    "    \"\"\"\n",
    "    by_block: dict[int, list[str]] = {}\n",
    "    for info in files_info:\n",
    "        block = int(info[\"block\"])\n",
    "        files = sorted(glob.glob(info[\"filename\"]))\n",
    "        if not files:\n",
    "            continue\n",
    "        by_block.setdefault(block, []).extend(files)\n",
    "\n",
    "    if not by_block:\n",
    "        print(\"nothing to process\")\n",
    "        return\n",
    "\n",
    "    bad = _bad_expr()\n",
    "\n",
    "    for block in sorted(by_block):\n",
    "        files = sorted(set(by_block[block]))\n",
    "        print(f\"\\n[{decay_label}] block={block} | {len(files)} file(s)\")\n",
    "\n",
    "        rdf = r.RDataFrame(treename, files)\n",
    "\n",
    "        # Check block name and exclude bad runs\n",
    "        base = rdf.Filter(f\"(block == {block}) && ({bad})\")\n",
    "\n",
    "        # ---- per-block ----\n",
    "        n_block = int(base.Count().GetValue())\n",
    "        cols_block = [str(c) for c in base.GetColumnNames()]\n",
    "        base.Snapshot(treename, str(_outfile(decay_label, block, fill=None)), cols_block, SNAPSHOT_OPTS)\n",
    "        print(f\"per-block  -> {_outfile(decay_label, block, fill=None)}  ({n_block} entries)\")\n",
    "\n",
    "        # ---- per-FILL ----\n",
    "        try:\n",
    "            fills = sorted(set(map(int, base.AsNumpy(['FILL'])['FILL'])))\n",
    "        except Exception as e:\n",
    "            print(f\"cannot read FILL: {e}; skip per-FILL\")\n",
    "            continue\n",
    "\n",
    "        print(f\"fills: {len(fills)}\")\n",
    "        for F in fills:\n",
    "            sub = base.Filter(f\"FILL == {F}\")\n",
    "            nF = int(sub.Count().GetValue())\n",
    "            if nF < MIN_ENTRIES:\n",
    "                print(f\"  skip F{F}: {nF} < {MIN_ENTRIES}\")\n",
    "                continue\n",
    "            cols_sub = [str(c) for c in sub.GetColumnNames()]\n",
    "            sub.Snapshot(treename, str(_outfile(decay_label, block, fill=F)), cols_sub, SNAPSHOT_OPTS)\n",
    "            print(f\"  F{F} -> {_outfile(decay_label, block, fill=F)}  ({nF} entries)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[B2OC] block=5 | 1 file(s)\n",
      "per-block  -> data/processed/2024_B2OC_B5.root  (12453113 entries)\n",
      "fills: 25\n",
      "  F10059 -> data/processed/2024_B2OC_B5_F10059.root  (97942 entries)\n",
      "  F10061 -> data/processed/2024_B2OC_B5_F10061.root  (299599 entries)\n",
      "  F10066 -> data/processed/2024_B2OC_B5_F10066.root  (336671 entries)\n",
      "  F10069 -> data/processed/2024_B2OC_B5_F10069.root  (757938 entries)\n",
      "  F10070 -> data/processed/2024_B2OC_B5_F10070.root  (108898 entries)\n",
      "  F10072 -> data/processed/2024_B2OC_B5_F10072.root  (732723 entries)\n",
      "  F10073 -> data/processed/2024_B2OC_B5_F10073.root  (770704 entries)\n",
      "  F10074 -> data/processed/2024_B2OC_B5_F10074.root  (737512 entries)\n",
      "  F10075 -> data/processed/2024_B2OC_B5_F10075.root  (194991 entries)\n",
      "  F10077 -> data/processed/2024_B2OC_B5_F10077.root  (548795 entries)\n",
      "  F10082 -> data/processed/2024_B2OC_B5_F10082.root  (142982 entries)\n",
      "  F10084 -> data/processed/2024_B2OC_B5_F10084.root  (1366337 entries)\n",
      "  F10086 -> data/processed/2024_B2OC_B5_F10086.root  (216097 entries)\n",
      "  F10087 -> data/processed/2024_B2OC_B5_F10087.root  (741841 entries)\n",
      "  F10090 -> data/processed/2024_B2OC_B5_F10090.root  (696011 entries)\n",
      "  F10091 -> data/processed/2024_B2OC_B5_F10091.root  (335774 entries)\n",
      "  F10092 -> data/processed/2024_B2OC_B5_F10092.root  (859782 entries)\n",
      "  F10093 -> data/processed/2024_B2OC_B5_F10093.root  (160265 entries)\n",
      "  F10094 -> data/processed/2024_B2OC_B5_F10094.root  (199742 entries)\n",
      "  F10095 -> data/processed/2024_B2OC_B5_F10095.root  (825116 entries)\n",
      "  F10096 -> data/processed/2024_B2OC_B5_F10096.root  (298704 entries)\n",
      "  F10097 -> data/processed/2024_B2OC_B5_F10097.root  (675110 entries)\n",
      "  F10098 -> data/processed/2024_B2OC_B5_F10098.root  (294110 entries)\n",
      "  F10099 -> data/processed/2024_B2OC_B5_F10099.root  (345589 entries)\n",
      "  F10100 -> data/processed/2024_B2OC_B5_F10100.root  (709880 entries)\n",
      "\n",
      "[B2OC] block=6 | 1 file(s)\n"
     ]
    }
   ],
   "source": [
    "# Process and clean (create process files) for D-Pi\n",
    "process_blocks(files_info_b2oc, treename=\"ST-b2oc\", decay_label=\"B2OC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2146ab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and clean (create process files) for J/Psi-K\n",
    "process_blocks(files_info_b2cc, treename=\"ST-b2cc\", decay_label=\"B2CC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea56dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree: ST-b2oc\n",
      "Entries: 11683229\n",
      "Branches:\n",
      "  - event\n",
      "  - run\n",
      "  - block\n",
      "  - GPSTIME\n",
      "  - FILL\n",
      "  - nLongTracks\n",
      "  - nPVs\n",
      "  - nVeloTracks\n",
      "  - Bp_DTF_OwnPV_CHI2DOF\n",
      "  - Bp_DTF_OwnPV_MASS\n",
      "  - Bp_DTF_OwnPV_CTAU\n",
      "  - Bp_DTF_OwnPV_CTAUERR\n",
      "  - Bp_DTF_OwnPV_FD\n",
      "  - Bp_M\n",
      "  - Bp_PT\n",
      "  - Bp_P\n",
      "  - Bp_BPVIPCHI2\n",
      "  - Db_M\n",
      "  - Db_PT\n",
      "  - Db_P\n",
      "  - Db_BPVIPCHI2\n",
      "  - Kp_TRCHI2\n",
      "  - Kp_PT\n",
      "  - Kp_P\n",
      "  - Kp_BPVIPCHI2\n",
      "  - Kp_PID_K\n",
      "  - Kp_PROBNN_K\n",
      "  - Kp_PROBNN_PI\n",
      "  - pim_TRCHI2\n",
      "  - pim_PT\n",
      "  - pim_P\n",
      "  - pim_PID_K\n",
      "  - pim_BPVIPCHI2\n",
      "  - pim_PROBNN_K\n",
      "  - pim_PROBNN_PI\n",
      "  - pip_PARTICLE_ID\n",
      "  - pip_TRCHI2\n",
      "  - pip_PT\n",
      "  - pip_P\n",
      "  - pip_BPVIPCHI2\n",
      "  - pip_PID_K\n",
      "  - pip_PROBNN_K\n",
      "  - pip_PROBNN_PI\n",
      "  - nFTClusters\n",
      "  - nUTClusters\n",
      "  - nVPClusters\n"
     ]
    }
   ],
   "source": [
    "# Quick check of one output file (or input files, but for that we need to change the path to DATA_RAW)\n",
    "# This code is only for the purpose of manual inspection\n",
    "file_to_check = DATA_PROCESSED / \"2024_B2CC_B8_F10232.root\"\n",
    "\n",
    "if not Path(file_to_check).exists():\n",
    "    print(f\"File not found: {file_to_check}\")\n",
    "else:\n",
    "    f = r.TFile.Open(str(file_to_check))\n",
    "    if not f or f.IsZombie():\n",
    "        print(f\"Could not open file: {file_to_check}\")\n",
    "    else:\n",
    "        tree = None\n",
    "        for name in (\"ST-b2cc\", \"ST-b2oc\"):\n",
    "            obj = f.Get(name)\n",
    "            if obj and obj.InheritsFrom(\"TTree\"):\n",
    "                tree = obj\n",
    "                break\n",
    "\n",
    "        if tree is None:\n",
    "            print(\"No TTree found in file.\")\n",
    "        else:\n",
    "            print(f\"Tree: {tree.GetName()}\")\n",
    "            print(f\"Entries: {tree.GetEntries()}\")\n",
    "            print(\"Branches:\")\n",
    "            for branch in tree.GetListOfBranches():\n",
    "                print(f\"  - {branch.GetName()}\")\n",
    "\n",
    "        f.Close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
