{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610162d9",
   "metadata": {},
   "source": [
    "# Notebook: de-duplicate per event by Bp_P clustering\n",
    "\n",
    "Per file and per event:\n",
    "- drop entries with `Bp_P ≤ 0` if any exist\n",
    "- cluster by relative difference in `Bp_P` (threshold `epsilon`) for entries of same event\n",
    "- keep one representative per cluster (random selection)\n",
    "- write cleaned file and print duplicate stats before/after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc1a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as r\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "import os\n",
    "import random\n",
    "\n",
    "r.ROOT.EnableImplicitMT()\n",
    "\n",
    "# I/O\n",
    "BASE_IN  = Path(\"data/processed\")\n",
    "BASE_OUT = Path(\"data/processed_clean_bp_p\")\n",
    "BASE_OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Clustering threshold (relative). 0.005 = 0.5%\n",
    "EPSILON = 0.005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123d683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _list_root_files(root_dir: Path, include: Optional[str] = None) -> List[Path]:\n",
    "    \"\"\"All .root files under root_dir. Optional filename filter.\"\"\"\n",
    "    files = sorted(root_dir.rglob(\"*.root\"))\n",
    "    if include:\n",
    "        files = [f for f in files if include in f.name]\n",
    "    return files\n",
    "\n",
    "def _open_tree(filename: Path, treename: str):\n",
    "    \"\"\"Open ROOT file and get tree by name. Returns (file, tree) or (None, None).\"\"\"\n",
    "    f = r.TFile.Open(str(filename))\n",
    "    if not f or f.IsZombie():\n",
    "        print(f\"skip (cannot open): {filename}\")\n",
    "        return None, None\n",
    "    t = f.Get(treename)\n",
    "    if not t or not t.InheritsFrom(\"TTree\"):\n",
    "        f.Close()\n",
    "        return None, None\n",
    "    return f, t\n",
    "\n",
    "def _choose_representative(bp_p_list: List[Tuple[float, int]]) -> int:\n",
    "    \"\"\"Pick a random entry index from the list.\"\"\"\n",
    "    return random.choice(bp_p_list)[1]\n",
    "\n",
    "def _cluster_keep_indices_fast(bp_p_list: List[Tuple[float, int]], epsilon: float) -> set:\n",
    "    \"\"\"\n",
    "    Cluster consecutive values in log-space with a relative threshold.\n",
    "\n",
    "    Here is the math of the logic:\n",
    "      We want entries p_i, p_{i-1} to be in the same cluster if their\n",
    "      relative difference is at most ε:\n",
    "\n",
    "          |p_i - p_{i-1}| / p_{i-1} <= ε          (1)\n",
    "\n",
    "      Assuming sorted order p_i >= p_{i-1} > 0, this is equivalent to\n",
    "\n",
    "          p_i / p_{i-1} <= 1 + ε                  (2)\n",
    "\n",
    "      Taking logs:\n",
    "\n",
    "          log(p_i) - log(p_{i-1}) <= log(1 + ε)   (3)\n",
    "\n",
    "      So in code we set gap_max = log1p(ε) and split a cluster whenever\n",
    "\n",
    "          log(p_i) - log(p_{i-1}) > gap_max.\n",
    "\n",
    "    From each cluster, keep one representative (chosen randomly).\n",
    "    \"\"\"\n",
    "    if len(bp_p_list) <= 1:\n",
    "        return {bp_p_list[0][1]} if bp_p_list else set()\n",
    "\n",
    "    # sort by p\n",
    "    bp_sorted = sorted(bp_p_list, key=lambda x: x[0])  # (p, idx)\n",
    "    logs = np.log([p for p, _ in bp_sorted])\n",
    "    gap_max = np.log1p(epsilon)\n",
    "\n",
    "    keep = set()\n",
    "    start = 0\n",
    "    n = len(bp_sorted)\n",
    "    # sweep once; split whenever the log-gap exceeds the threshold\n",
    "    for i in range(1, n):\n",
    "        if logs[i] - logs[i-1] > gap_max:\n",
    "            # finalize cluster [start, i)\n",
    "            keep.add(_choose_representative(bp_sorted[start:i]))\n",
    "            start = i\n",
    "    # last cluster\n",
    "    keep.add(_choose_representative(bp_sorted[start:n]))\n",
    "    return keep\n",
    "\n",
    "def _duplicate_stats_from_events(events: Dict[int, List[Tuple[float,int]]]) -> Tuple[int, int, float]:\n",
    "    \"\"\"\n",
    "    Given {event: [(p, idx), ...]}, return:\n",
    "      total_valid, duplicate_count, duplicate_fraction\n",
    "    duplicate_count sums (len(list)-1) over events with >1 entries.\n",
    "    \"\"\"\n",
    "    total = sum(len(v) for v in events.values())\n",
    "    dupes = sum(len(v) - 1 for v in events.values() if len(v) > 1)\n",
    "    frac = (dupes / total) if total > 0 else 0.0\n",
    "    return total, dupes, frac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_decay(base_in: Path, base_out: Path, include_token: str, treename: str, epsilon: float) -> None:\n",
    "    \"\"\"\n",
    "    Process only files whose name contains include_token (e.g., 'B2OC' or 'B2CC').\n",
    "    Remove duplicate entries for each event by grouping similar Bp_P values.\n",
    "    \"\"\"\n",
    "    # Ensure output dir exists and is writable\n",
    "    base_out.mkdir(parents=True, exist_ok=True)\n",
    "    if not os.access(base_out, os.W_OK):\n",
    "        raise PermissionError(f\"Output directory not writable: {base_out}\")\n",
    "\n",
    "    files = _list_root_files(base_in, include=include_token)\n",
    "    if not files:\n",
    "        print(f\"no .root files under {base_in} matching '{include_token}'\")\n",
    "        return\n",
    "\n",
    "    for fpath in files:\n",
    "        fin, t = _open_tree(fpath, treename)\n",
    "        if not t:\n",
    "            print(f\"skip (tree '{treename}' not found) in {fpath.name}\")\n",
    "            if fin: fin.Close()\n",
    "            continue\n",
    "\n",
    "        # Read only what's needed for the scan (I/O speedup)\n",
    "        t.SetBranchStatus(\"*\", 0)\n",
    "        t.SetBranchStatus(\"event\", 1)\n",
    "        t.SetBranchStatus(\"Bp_P\", 1)\n",
    "\n",
    "        # Collect per-event entries; skip Bp_P <= 0 or missing\n",
    "        events: Dict[int, List[Tuple[float, int]]] = {}\n",
    "        n = t.GetEntries()\n",
    "        zeros = 0\n",
    "        missing = 0\n",
    "        for i in range(n):\n",
    "            t.GetEntry(i)\n",
    "            try:\n",
    "                ev = int(getattr(t, \"event\"))\n",
    "                p  = float(getattr(t, \"Bp_P\"))\n",
    "            except Exception:\n",
    "                missing += 1\n",
    "                continue\n",
    "            if not np.isfinite(p) or p <= 0.0:\n",
    "                zeros += 1\n",
    "                continue\n",
    "            events.setdefault(ev, []).append((p, i))\n",
    "\n",
    "        total_before, dupes_before, frac_before = _duplicate_stats_from_events(events)\n",
    "        print(f\"{fpath.name}: valid={total_before}, zeros={zeros}, missing={missing}, duplicates(before)={dupes_before} ({frac_before:.3%})\")\n",
    "\n",
    "        # If nothing valid, skip writing, and exit\n",
    "        if total_before == 0:\n",
    "            fin.Close()\n",
    "            print(f\"No valid entries; skipping write for {fpath.name}\")\n",
    "            exit()\n",
    "\n",
    "        # Build keep indices via clustering\n",
    "        keep: set = set()\n",
    "        for bp_list in events.values():\n",
    "            keep |= _cluster_keep_indices_fast(bp_list, epsilon)\n",
    "\n",
    "        fin.Close()\n",
    "\n",
    "        # Write cleaned file via TEntryList + CopyTree\n",
    "        out_path = base_out / fpath.name\n",
    "        fout = r.TFile(str(out_path), \"RECREATE\")\n",
    "        if not fout or fout.IsZombie():\n",
    "            print(f\"ERROR: cannot create output file: {out_path}\")\n",
    "            if fout: fout.Close()\n",
    "            exit()\n",
    "\n",
    "        fin2 = r.TFile.Open(str(fpath))\n",
    "        if not fin2 or fin2.IsZombie():\n",
    "            print(f\"ERROR: cannot reopen input file for writing stage: {fpath}\")\n",
    "            fout.Close()\n",
    "            if fin2: fin2.Close()\n",
    "            exit()\n",
    "\n",
    "        t2 = fin2.Get(treename)\n",
    "        if not t2 or not t2.InheritsFrom(\"TTree\"):\n",
    "            print(f\"ERROR: tree '{treename}' missing when rewriting {fpath.name}\")\n",
    "            fin2.Close(); fout.Close()\n",
    "            exit()\n",
    "\n",
    "        # Build entry list of kept indices\n",
    "        elist = r.TEntryList(\"elist\", \"kept entries\")\n",
    "        for i in sorted(keep):\n",
    "            elist.Enter(i)\n",
    "\n",
    "        t2.SetEntryList(elist)\n",
    "        newt = t2.CopyTree(\"\")\n",
    "        newt.Write()\n",
    "\n",
    "        fout.Write()\n",
    "        fout.Close()\n",
    "        fin2.Close()\n",
    "\n",
    "        # Post-check on written file\n",
    "        fcheck = r.TFile.Open(str(out_path))\n",
    "        if not fcheck or fcheck.IsZombie():\n",
    "            print(f\"ERROR: cannot open written file for check: {out_path}\")\n",
    "            if fcheck: fcheck.Close()\n",
    "            exit()\n",
    "\n",
    "        tcheck = fcheck.Get(treename)\n",
    "        if not tcheck or not hasattr(tcheck, \"GetEntries\"):\n",
    "            print(f\"ERROR: written file has no tree '{treename}' (write failure?).\")\n",
    "            fcheck.ls()\n",
    "            fcheck.Close()\n",
    "            exit()\n",
    "\n",
    "        n_after = int(tcheck.GetEntries())\n",
    "        events_after: Dict[int, List[int]] = {}\n",
    "        # read only event branch for the check\n",
    "        tcheck.SetBranchStatus(\"*\", 0)\n",
    "        tcheck.SetBranchStatus(\"event\", 1)\n",
    "        for i in range(n_after):\n",
    "            tcheck.GetEntry(i)\n",
    "            ev = int(getattr(tcheck, \"event\"))\n",
    "            events_after.setdefault(ev, []).append(i)\n",
    "\n",
    "        dupes_after = sum(len(v) - 1 for v in events_after.values() if len(v) > 1)\n",
    "        frac_after = (dupes_after / n_after) if n_after > 0 else 0.0\n",
    "        fcheck.Close()\n",
    "\n",
    "        print(f\" -> cleaned: kept={n_after} / {total_before}, duplicates(after)={dupes_after} ({frac_after:.3%})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39d412c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024_B2OC_B5.root: valid=12453113, zeros=0, missing=0, duplicates(before)=260306 (2.090%)\n"
     ]
    }
   ],
   "source": [
    "# B2OC\n",
    "clean_decay(BASE_IN, BASE_OUT, include_token=\"B2OC\", treename=\"ST-b2oc\", epsilon=EPSILON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dee1327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned outputs — B2OC:\n",
      "2024_B2OC_B5.root: 12453113 entries, duplicates=260306 (2.090%)\n",
      "2024_B2OC_B5_F10059.root: 97942 entries, duplicates=2204 (2.250%)\n",
      "2024_B2OC_B5_F10061.root: 299599 entries, duplicates=6404 (2.138%)\n",
      "2024_B2OC_B5_F10066.root: 336671 entries, duplicates=7171 (2.130%)\n",
      "2024_B2OC_B5_F10069.root: 757938 entries, duplicates=16152 (2.131%)\n",
      "2024_B2OC_B5_F10070.root: 108898 entries, duplicates=2213 (2.032%)\n",
      "2024_B2OC_B5_F10072.root: 732723 entries, duplicates=15052 (2.054%)\n",
      "2024_B2OC_B5_F10073.root: 770704 entries, duplicates=16132 (2.093%)\n",
      "2024_B2OC_B5_F10074.root: 737512 entries, duplicates=15185 (2.059%)\n",
      "2024_B2OC_B5_F10075.root: 194991 entries, duplicates=4008 (2.055%)\n",
      "2024_B2OC_B5_F10077.root: 548795 entries, duplicates=11497 (2.095%)\n",
      "\n",
      "Cleaned outputs — B2CC:\n",
      "no files in data/processed for token B2CC\n"
     ]
    }
   ],
   "source": [
    "def final_report(base_out: Path, treename: str, include_token: str):\n",
    "    files = _list_root_files(base_out, include=include_token)\n",
    "    if not files:\n",
    "        print(f\"no files in {base_out} for token {include_token}\")\n",
    "        return\n",
    "    for fpath in files:\n",
    "        try:\n",
    "            f = r.TFile.Open(str(fpath))\n",
    "            if not f or f.IsZombie():\n",
    "                print(f\"skip (cannot open): {fpath}\")\n",
    "                continue\n",
    "        except OSError as e:\n",
    "            print(f\"skip (OSError opening file): {fpath} — {e}\")\n",
    "            continue\n",
    "        t = f.Get(treename)\n",
    "        if not t or not t.InheritsFrom(\"TTree\"):\n",
    "            print(f\"{fpath.name}: no tree '{treename}'\")\n",
    "            f.Close()\n",
    "            continue\n",
    "        n = int(t.GetEntries())\n",
    "        t.SetBranchStatus(\"*\", 0)\n",
    "        t.SetBranchStatus(\"event\", 1)\n",
    "        events = []\n",
    "        for i in range(n):\n",
    "            t.GetEntry(i)\n",
    "            events.append(int(getattr(t, \"event\")))\n",
    "        counts = Counter(events)\n",
    "        dupes = sum(c - 1 for c in counts.values() if c > 1)\n",
    "        frac = (dupes / n) if n > 0 else 0.0\n",
    "        print(f\"{fpath.name}: {n} entries, duplicates={dupes} ({frac:.3%})\")\n",
    "        f.Close()\n",
    "\n",
    "print(\"\\nCleaned outputs — B2OC:\")\n",
    "final_report(BASE_IN, \"ST-b2oc\", \"B2OC\")\n",
    "\n",
    "print(\"\\nCleaned outputs — B2CC:\")\n",
    "final_report(BASE_IN, \"ST-b2cc\", \"B2CC\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
